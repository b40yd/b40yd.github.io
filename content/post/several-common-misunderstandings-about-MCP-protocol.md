+++
title = "关于 MCP 协议的几个常见理解误区"
date = 2025-04-30
lastmod = 2025-04-30T14:27:42+08:00
tags = ["agent", "mcp"]
categories = ["agent", "mcp"]
draft = false
author = "B40yd"
+++

## 关于 MCP 协议的几个常见理解误区 {#关于-mcp-协议的几个常见理解误区}

MCP（Model Context Protocol，模型上下文协议）是近年来在大模型应用开发中逐渐受到关注的一项交互协议。它旨在通过标准化的方式为模型提供更丰富的上下文信息，从而提升问答或推理的准确性与效率。然而，在实际推广和应用过程中，围绕 MCP 出现了不少误解。本文将梳理并澄清 关于 MCP 的三个主要理解误区 。


### 误区一：MCP 协议需要大模型支持 {#误区一-mcp-协议需要大模型支持}


### 背景说明 {#背景说明}

MCP 的核心目标是帮助应用层更好地为大模型补充上下文信息，以提升其回答质量。它本身并不是一种依赖特定模型能力的功能模块，而是一个指导性的协议标准 。


### 常见做法对比 {#常见做法对比}

在 MCP 出现之前，常见的补充上下文方式包括：

-   记忆存储 ：保存历史对话记录作为上下文；
-   RAG（Retrieval-Augmented Generation） ：从知识库或互联网中检索信息作为补充；
-   Function Calling ：调用外部工具获取动态数据。

这些方法本质上都是为了让模型“看到”更多有用信息，而 MCP 的作用就是标准化这一过程 。


### 结论 {#结论}

> MCP 并不依赖于任何具体的大模型，即使是 GPT-2 这样的旧模型也可以使用 MCP 来增强上下文输入。


### 误区二：只有支持 Function Calling 的模型才支持 MCP 协议 {#误区二-只有支持-function-calling-的模型才支持-mcp-协议}


### 理解 Function Calling {#理解-function-calling}

首先我们需要明确 Function Calling 是一种交互范式 ，流程如下：

1.  应用层提供一组可调用的工具；
2.  大模型根据问题进行意图识别，选择合适的工具并返回参数；
3.  应用层调用该工具，将结果反馈给模型用于生成回答。

在这个模式中有三个关键角色：应用、资源方、大模型 。


### MCP 是对 Function Calling 的包装与升级 {#mcp-是对-function-calling-的包装与升级}

MCP 在结构上扩展了 Function Calling，引入了新的三层架构：

-   角色定义：主机、客户端、服务器。
-   实际运行中，MCP 将 “客户端-服务器” 视为一个黑盒，整体与资源方进行交互。

最终形成了四个角色：

-   主机应用
-   客户端-服务器黑盒
-   资源方
-   大模型


### MCP vs Function Calling {#mcp-vs-function-calling}

| 特性   | Function Calling  | MCP          |
|------|-------------------|--------------|
| 工具来源 | 应用直接定义      | 通过 MCP 服务器获取 |
| 接入成本 | 高，需重复编码    | 低，标准化接入 |
| 工具调用机制 | 一致              | 一致         |
| 对模型要求 | 需要具备 Pick Tool 能力 | 同上         |
|        |                   |              |

虽然大模型是否支持 Function Calling会影响 Pick Tool 的准确度，但这并不影响 MCP 协议本身的可用性。甚至可以通过 **提示词工程** 模拟 Pick Tool 行为。


### 结论 {#结论}

> 不支持 Function Calling 的模型，依然可以借助提示词等手段使用 MCP 协议来补充上下文。


### 误区三：大模型原生支持 MCP 协议 {#误区三-大模型原生支持-mcp-协议}


### 概念再澄清 {#概念再澄清}

所谓“原生支持”，通常是指大模型内部已经集成了某项功能或协议。对于 MCP 来说，这意味着模型内置了大量按 MCP 协议定义的工具，并能自主调用它们。

这听起来很理想，但在现实中几乎不可行。


### 不可行的原因分析 {#不可行的原因分析}

1.  资源种类繁多且不断更新
    -   互联网上的可访问资源数以亿计，且持续变化。
    -   MCP 服务器及其中的工具也是海量且动态的，无法被全部内化进模型中。

2.  鉴权与隐私问题
    -   很多资源需要用户身份验证、API Key 等私有凭证。
    -   模型训练时不可能预加载这些敏感信息。

3.厂商宣传误导

-   一些模型厂商可能只是在其配套的 Agent 框架中加入了对 MCP 的支持。
-   但将其称为“大模型原生支持 MCP”，容易引起误解。


### 结论 {#结论}

> 目前没有任何大模型能够真正原生支持 MCP 协议。所谓“原生支持”往往只是框架层面的支持，而非模型本身的特性。


## 总结 {#总结}

MCP 是一种帮助应用层更好地为大模型提供上下文信息的协议标准，它的设计初衷是为了提高上下文补充的效率与通用性。我们应当理性看待以下几个关键点：

-   MCP **不需要特定模型的支持** ；
-   即使模型 **不支持 Function Calling** ，也能使用 MCP；
-   **没有大模型能原生支持 MCP 协议** ，相关说法大多是术语误用或营销误导。

正确认识 MCP，有助于我们在构建 AI 应用时做出更合理的架构设计与技术选型。
